{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import struct\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = str(pathlib.Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = base_path+\"/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_MNIST(dataset: str=\"training\", path: str=\"./\") -> Union[Tuple[np.ndarray,np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reads in the MNIST data\n",
    "    This function allows specification of the part to be read (training/testing/validation)\n",
    "    Note that if dataset='testing', no labels will be returned\n",
    "    \"\"\"\n",
    "    \n",
    "    #Figure out the name of the file to load    \n",
    "    if dataset.lower() == \"training\":\n",
    "        file_name_suffix = 'train'\n",
    "        has_labels = True\n",
    "    \n",
    "    elif dataset.lower() == \"validation\":\n",
    "        file_name_suffix = 'val'\n",
    "        has_labels = True\n",
    "\n",
    "    elif dataset.lower() == \"testing\":\n",
    "        file_name_suffix = 'test'\n",
    "        has_labels = True\n",
    "\n",
    "    else:\n",
    "        print(\"dataset must be 'testing','validation', or 'training'\")\n",
    "        raise ValueError\n",
    "    \n",
    "    #Load the appropriate files\n",
    "    X = np.load(mnist_data+'X'+file_name_suffix+'.npy')\n",
    "    if has_labels:\n",
    "        y = np.load(mnist_data+'y'+file_name_suffix+'.npy')\n",
    "    \n",
    "    X = np.float64(X).reshape(X.shape[0],-1)\n",
    "    y = y.flatten().astype('int')\n",
    "    \n",
    "    #Return the appropriate data\n",
    "    if has_labels:\n",
    "        return X,y\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "\n",
    "def show_MNIST_example(image) -> None:\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 array of pixel data as an image.\n",
    "    \"\"\"\n",
    "    image = image[-28**2:]\n",
    "    image = image.reshape(28,28)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image\n",
      "Class: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the data and visualize a training example\n",
    "X,y = read_MNIST(\"training\")\n",
    "print(\"Training image\")\n",
    "print(f\"Class: {y[10]}\")\n",
    "show_MNIST_example(X[10])\n",
    "\n",
    "X_val,y_val = read_MNIST(\"validation\")\n",
    "X_test, y_test = read_MNIST(\"testing\")\n",
    "\n",
    "# let's shuffle the data\n",
    "np.random.seed(789123)\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Building block of the Decision Tree.\n",
    "    \"\"\"\n",
    "    left = None  # left child\n",
    "    right = None  # right child\n",
    "    index = None  # feature index (what is the feature by which we split)\n",
    "    val = None  # what's the value at which we split\n",
    "    # Once you arrive at a leaf Node then we use labels\n",
    "    is_leaf = True\n",
    "    label = None\n",
    "    \n",
    "    def __init__(self, left=None, right=None, index=None, val=None, is_leaf=True, label=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.val = val\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        \n",
    "    def classify(self, x):\n",
    "        # this is a recursive function, following the path to the correct leaf\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        elif x[self.index] <= self.val:\n",
    "            return self.left.classify(x)\n",
    "        elif x[self.index] > self.val:\n",
    "            return self.right.classify(x)\n",
    "        \n",
    "            \n",
    "    def classify_set(self, X):\n",
    "        # work on examples in a loop \n",
    "        res = []\n",
    "        for sample in X:\n",
    "            res.append(self.classify(sample))\n",
    "        return np.asarray(res)\n",
    "            \n",
    "    #useful for debugging (on small trees)\n",
    "    def print_tree(self) -> None:\n",
    "        print(f\"index = {self.index}, val = {self.val}, leaf = {self.is_leaf}, label = {self.label}, left = {self.left}, right = {self.right}\")\n",
    "        if self.left is not None:\n",
    "            print(\"left = \", end=\"\")\n",
    "            self.left.print_tree()\n",
    "        if self.right is not None:\n",
    "            print(\"right = \", end=\"\")\n",
    "            self.right.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to classify a leaf node take the mode of the labels that arrive at the leaf\n",
    "def label_leaf(labels: np.ndarray) -> int:\n",
    "    classes, counts = np.unique(labels, return_counts=True)\n",
    "    return classes[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_gini(features: np.ndarray, labels: np.ndarray, min_split_size: int=5):\n",
    "    \"\"\"\n",
    "    Given a set of feature values (for a single feature) and the corresponding labels,\n",
    "    find the split that minimizes the (weighted by size) sum of the Gini indices of the two parts\n",
    "    Note: the combined Gini index is given by len(L)*G[0]+len(U)*G[1]\n",
    "\n",
    "    Returns: (tau, G, L, U)\n",
    "        tau : the threshold to split\n",
    "        G : 2-tuple with the Gini indices of the two parts\n",
    "        L, U : indices of the points that go into L and U\n",
    "    \"\"\"\n",
    "    \n",
    "    # sort the feature values (and permute the labels to match that order)\n",
    "    order = np.argsort(features)\n",
    "    x = features[order]\n",
    "    y = labels[order]\n",
    "    N = len(x)\n",
    "    classes = np.unique(labels)\n",
    "    \n",
    "    # check if there is nothing to split\n",
    "    if (x[0]==x[-1]) or (len(classes)==1):\n",
    "        return None, [np.inf,np.inf], range(N), None    \n",
    "    \n",
    "    # freq_u maintains frequencies of labels in the (potential) upper portion of the split,\n",
    "    # and freq_l in the lower\n",
    "    \n",
    "    freq_u = np.zeros(np.max(classes) + 1)\n",
    "    for c in range(len(freq_u)):\n",
    "        freq_u[c] = np.mean(labels==c)\n",
    "    freq_l = np.zeros(np.max(classes) + 1)\n",
    "    \n",
    "    # now go over the examples in order of increasing feature value;\n",
    "    # consider splitting before each index where the value changes\n",
    "    # rather that computing the Gini index from scratch for every split, we will keep track\n",
    "    # of the running frequencies (as we traverse the list of examples ordered by feature value)\n",
    "    # and simply recompute Gini from the frequencies each step (much faster)\n",
    "    \n",
    "    gini=dict()\n",
    "    splits=dict()\n",
    "    for i in range(N-1):\n",
    "        # update frequencies\n",
    "        freq_l[y[i]] += 1/N\n",
    "        freq_u[y[i]] -= 1/N\n",
    "        \n",
    "        if x[i+1] > x[i]: # split here, between i and i+1?\n",
    "            tau = (x[i+1] + x[i]) / 2.0\n",
    "            \n",
    "            gini_l = np.dot(freq_l, 1-freq_l)\n",
    "            gini_u = np.dot(freq_u, 1-freq_u)\n",
    "            \n",
    "            gini[tau] = (i * gini_l + (N-i) * gini_u, gini_l, gini_u)\n",
    "            splits[tau] = i+1 # index of the first element that goes to U\n",
    "\n",
    "    # now find the best split\n",
    "    best_tau = -1\n",
    "    bestval = np.inf\n",
    "    for t in gini:\n",
    "        if gini[t][0] < bestval:\n",
    "            best_tau = t\n",
    "            bestval = gini[t][0]\n",
    "    \n",
    "    L = order[:splits[best_tau]]\n",
    "    U = order[splits[best_tau]:]\n",
    "    \n",
    "    return best_tau, gini[best_tau][1:], L, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X: np.ndarray, y: np.ndarray, min_split_size: int=5, bag_size: Union[None, int]=None):\n",
    "    # Find the best way to split the data in X (with labels y) by a single feature\n",
    "    # Don't split \n",
    "    \n",
    "    if X.shape[0] < min_split_size:\n",
    "        return None\n",
    "    \n",
    "    if bag_size is not None: # bagging\n",
    "        feature_subset = np.random.choice(X.shape[1], bag_size, replace=False)\n",
    "        X = X[:, feature_subset]\n",
    "    else:\n",
    "        feature_subset = np.arange(X.shape[1])\n",
    "    \n",
    "    opt = None\n",
    "    bestgini = np.inf\n",
    "    for d in range(X.shape[1]):\n",
    "        tau_d, gini_d, L_d, U_d = best_split_gini(X[:,d], y)\n",
    "        if (tau_d is None):\n",
    "            continue\n",
    "        gini = len(L_d) * gini_d[0] + len(U_d) * gini_d[1]\n",
    "        if gini < bestgini:\n",
    "            bestgini = gini\n",
    "            opt = {'d':feature_subset[d], \n",
    "                   'tau':tau_d, \n",
    "                   'Gini':gini, \n",
    "                   'Gini-parts':gini_d, \n",
    "                   'L': L_d, \n",
    "                   'U': U_d}\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_tree(\n",
    "    root: Node, \n",
    "    data: np.ndarray, \n",
    "    labels: np.ndarray, \n",
    "    depth: int=1, \n",
    "    max_depth: int=1, \n",
    "    min_split_size: int=1, \n",
    "    bag_size: Union[None, int]=None) -> Node:\n",
    "    # this takes root (a node associated with data/labels, and existing at the given depth)\n",
    "    # and builds a tree rooted at that node, not to exceed the given max_depth\n",
    "   \n",
    "    if (depth == max_depth):\n",
    "        no_split=True\n",
    "    else:\n",
    "        best_split = split_data(data, labels, min_split_size, bag_size)\n",
    "        if best_split==None:\n",
    "            no_split=True\n",
    "        else: # splitting!\n",
    "            no_split=False\n",
    "            root.index = best_split['d']\n",
    "            root.val = best_split['tau']\n",
    "            root.left = grow_tree(Node(), data[best_split['L']], labels[best_split['L']], depth+1, max_depth,min_split_size, bag_size)\n",
    "            root.right = grow_tree(Node(), data[best_split['U']], labels[best_split['U']], depth+1, max_depth,min_split_size, bag_size)\n",
    "            root.is_leaf = False\n",
    "            \n",
    "    if no_split:\n",
    "        label = label_leaf(labels)\n",
    "        root.is_leaf = True\n",
    "        root.label = label\n",
    "        \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data:np.ndarray, labels:np.ndarray, max_depth:float=np.inf, min_split_size:int=5, bag_size: Union[None, int]=None) -> Node:\n",
    "    root=Node()\n",
    "    tree=grow_tree(root,\n",
    "                   data,\n",
    "                   labels,\n",
    "                   depth=0,\n",
    "                   max_depth=max_depth,\n",
    "                   min_split_size=min_split_size,\n",
    "                   bag_size=bag_size)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = build_tree(X, y, max_depth=10, min_split_size=3, bag_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation accuracy for the tree (ToDo)\n",
    "- **Compute** training and validation accuracy\n",
    "- **Report** training and validation set accuracies of a single tree, with **hyperparameters** (max tree depth and minimum size of a leaf) tuned as you see fit (make sure to describe how you tuned them, and include the code and output from the process in the notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9096444444444445\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy = {np.mean(tree.classify_set(X) == y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 0.847\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Accuracy = {np.mean(tree.classify_set(X_val) == y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy (ToDo)\n",
    "\n",
    "- **Compute and report** the results on test set, for the model built with the chosen values – please don’t be tempted to evaluate the model on test more than once, so be sure you are done with the tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.8522\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy = {np.mean(tree.classify_set(X_test) == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the Tree (ToDo)\n",
    "\n",
    "- Add the code for pruning a tree\n",
    "- Report the accuracy of the CART tree (with pruning) using hyperparameters (including λ) tuned as you see fit, on the test set; \n",
    "- Compare it to the result with the unpruned tree, and comment on the difference, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for running bagging ensembles on data\n",
    "def apply_ensemble(trees: List[Node], data: np.ndarray, C: int=10):\n",
    "    \"\"\"Returns the labels after applying the ensemble\"\"\"\n",
    "    res = np.array([tree.classify_set(data) for tree in trees])\n",
    "    yhat = np.zeros(res.shape[1])\n",
    "    for i in range(res.shape[1]):\n",
    "        yhat[i]=np.argmax(np.bincount(res[:,i]))\n",
    "    return yhat.astype(int)\n",
    "\n",
    "def evaluate_ensemble(trees, data: np.ndarray, labels: np.ndarray):\n",
    "    \"\"\"Returns the accuracy of the ensemble\"\"\"\n",
    "    return np.mean(apply_ensemble(trees, data) == labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble (ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "def create_ensemble(X: np.ndarray, y: np.ndarray, max_depth: int=10, min_split_size: int=1, num_trees: int=5, bag_fraction=0.5) -> List[Node]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N, d = X.shape\n",
    "    assert 0 < bag_fraction < 1.0\n",
    "    bag_size = int(d*bag_fraction)\n",
    "    \n",
    "    trees = []\n",
    "    for _ in tqdm(range(num_trees)): # this will show progress bar\n",
    "        # To be filled out\n",
    "        \n",
    "        # sample data points (with replacement)\n",
    "        bag = np.random.choice(N, N, replace=True)\n",
    "        \n",
    "        # train the tree\n",
    "        tree = build_tree(X[bag,:], y[bag], max_depth, min_split_size, bag_size)\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB: This step takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [18:36<00:00, 37.23s/it]\n"
     ]
    }
   ],
   "source": [
    "ensemble = create_ensemble(X, y, max_depth=15, min_split_size=5, num_trees=30, bag_fraction=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Accuracy (ToDo)\n",
    "\n",
    "- **Compute** the training and validation accuracy\n",
    "\n",
    "- **Report** the training and validation set accuracies of your ensemble. You should aim to get at least **90%** validation accuracy.\n",
    "- **Plot** the val accuracy as a function of ensemble size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train acc: 0.8929\n",
      "mean val acc: 0.7783\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "train_acc = np.zeros(len(ensemble))\n",
    "val_acc = np.zeros(len(ensemble))\n",
    "for t in range(len(ensemble)):\n",
    "    train_acc[t]=np.mean(ensemble[t].classify_set(X)==y)\n",
    "    val_acc[t]=np.mean(ensemble[t].classify_set(X_val)==y_val)\n",
    "print('mean train acc: %.4f'%np.mean(train_acc))\n",
    "print('mean val acc: %.4f'%np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ensemble(ensemble, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy (ToDo)\n",
    "- **Compute and report** the results of your ensemble on the test set. Again, don’t do it more than once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9526"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ensemble(ensemble, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of the size of your ensemble (ToDo)\n",
    "\n",
    "- **Show the effect of the size of your ensemble as follows**: \n",
    "    - Let T be the number of trees in your ensemble. \n",
    "    - For t = 1, . . . , T \n",
    "        - **Compute** the validation set accuracy of the partial ensemble consisting of trees 1, . . . , t\n",
    "        - **Plot** this as a function of t. \n",
    "- Discuss what this tells you and how it may inform tuning T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
