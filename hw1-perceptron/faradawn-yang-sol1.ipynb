{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSet1 Coding Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# ^^ Predefined ‘magic function’ telling Jupyter to display images inline (rather than pop up a separate window)\n",
    "import matplotlib.image as mimg\n",
    "# ^^ package to help us read in images\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FashionMNIST contains 10 classes, labeled as 0,1,2,...,9 in the dataset. Below is the mapping between numeric labels and their actual classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict={0:'T-shirt/top',\n",
    "              1:'Trouser',\n",
    "              2:'Pullover',\n",
    "              3:'Dress',\n",
    "              4:'Coat',\n",
    "              5:'Sandal',\n",
    "              6:'Shirt',\n",
    "              7:'Sneaker',\n",
    "              8:'Bag',\n",
    "              9:'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataBase(basename,partition='train',N=None, shuffle=False,normalize=True):\n",
    "    '''\n",
    "    This function will create one database that will contain images with their lables\n",
    "    The data are supposed to be in the paths consisting of\n",
    "     <basename> / <partition> / <category> / <category>-<index>.jpg\n",
    "     e.g., FashionMNIST/val/4/4-37.jpg\n",
    "    Inputs:\n",
    "        basename (str)  : name of the folder containing all the data. It should be \"FashionMNIST\"\n",
    "        partition (str) : \"train\" or \"val\" or \"test\"\n",
    "        N (int)         : number of examples for each category; when N=None, all samples will be loaded\n",
    "        shuffle (bool)  : boolean value; if False, samples from category 0 will be returned first and samples from category 9 last\n",
    "                          if True, samples will be randomly shuffled\n",
    "        normalize (bool): boolean value; if True, samples are normalized to [-1,1]\n",
    "    Outputs:\n",
    "        database (list) : list of tuples (x,y). x is image data. y is numeric label of x \n",
    "        \n",
    "    '''\n",
    "    database=[]\n",
    "    for label in range(10):\n",
    "        n = len(os.listdir(os.path.join(basename,partition,str(label)))) if N is None else N\n",
    "        for i in range(n):          \n",
    "            imageName=os.path.join(basename,partition,str(label),str(label)+'-'+str(i)+'.jpg')\n",
    "            imageData=mimg.imread(imageName)\n",
    "            imageData = np.float32(imageData) if not normalize else np.float32(imageData)/255*2-1\n",
    "            database.append((imageData,label))\n",
    "    if shuffle:\n",
    "        random.shuffle(database)\n",
    "    return database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2ndarray(dataset):\n",
    "    '''\n",
    "    This function will take the output from makeDataBase() and return two numpy arrays: X and y\n",
    "    Inputs:\n",
    "        dataset (list): list of (sample, label) pairs\n",
    "    Outputs:\n",
    "        X (array)     : a 2D numpy array with size (N,D). N is the length of dataset, D is 28*28. \n",
    "                        Each row of X is an image sample flattened\n",
    "        y (array)     : a numpy array with size (N,). y contains numeric labels of corresponding samples\n",
    "    '''\n",
    "    num=len(dataset)\n",
    "    X = np.empty((num,28*28),dtype=np.float32)\n",
    "    y = np.empty((num,),dtype=int)\n",
    "    for i in range(num):\n",
    "        X[i] = dataset[i][0].flatten()\n",
    "        y[i] = dataset[i][1]\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_hat,y):\n",
    "    '''\n",
    "    This function takes predicted labels and ground truth labels and return accuracy\n",
    "    Inputs:\n",
    "        y_hat (array): (N,)-shaped numpy array containing predicted labels\n",
    "        y (array)    : (N,)-shaped numpy array containing ground truth labels\n",
    "    Outputs:\n",
    "        accu (float) : accuracy between [0.,1.]\n",
    "    '''\n",
    "    accu = np.count_nonzero(y_hat==y)/len(y)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we prepare data\n",
    "trainset = makeDataBase('FashionMNIST',partition='train',N=10, normalize=True)# Try different N:10/50/100/1000;\n",
    "trainX, trainy = list2ndarray(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now also load val and test (these are of fixed size)\n",
    "valset = makeDataBase('FashionMNIST',partition='val', normalize=True)\n",
    "testset = makeDataBase('FashionMNIST',partition='test', normalize=True)\n",
    "\n",
    "valX, valy = list2ndarray(valset)\n",
    "testX, testy = list2ndarray(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some Sanity check: visualize an image and print its class. Play with this a bit to familiarize yourself with the\n",
    "# kind of data you are working with\n",
    "plt.imshow(trainset[0][0],cmap='gray')\n",
    "plt.title(f'This is a {classes_dict[trainset[0][1]]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_matrix(A, B):\n",
    "    # source: https://www.dabblingbadger.com/blog/2020/2/27/implementing-euclidean-distance-matrix-calculations-from-scratch-in-python\n",
    "    M = A.shape[0]\n",
    "    N = B.shape[0]\n",
    "    A_dots = (A*A).sum(axis=1).reshape((M,1)) * np.ones(shape=(1,N))\n",
    "    B_dots = (B*B).sum(axis=1) * np.ones(shape=(M,1))\n",
    "    return A_dots + B_dots -2 * np.dot(A, B.transpose())\n",
    "\n",
    "def KNN_predict(trainX, trainy, testX, k):\n",
    "    N = len(trainX)\n",
    "    M = len(testX)\n",
    "    y_hat = [0] * M\n",
    "    D = dist_matrix(trainX, testX)\n",
    "    \n",
    "    for j in range(M):\n",
    "        arr = D[:, j].argsort()\n",
    "        type_cnt = np.array([0] * 10)\n",
    "        for val in arr[:k]:\n",
    "            type_cnt[trainy[val]] += 1\n",
    "        max_type = type_cnt.argmax()\n",
    "        y_hat[j] = max_type\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying out all combinations of k and N, select the optimal k and N and compute accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc, n, k: 0.6641 10 1\n",
      "acc, n, k: 0.6515 10 3\n",
      "acc, n, k: 0.6313 10 7\n",
      "acc, n, k: 0.5751 10 15\n",
      "acc, n, k: 0.5228 10 25\n",
      "acc, n, k: 0.7391 50 1\n",
      "acc, n, k: 0.7391 50 3\n",
      "acc, n, k: 0.7373 50 7\n",
      "acc, n, k: 0.7228 50 15\n",
      "acc, n, k: 0.711 50 25\n",
      "acc, n, k: 0.751 100 1\n",
      "acc, n, k: 0.7533 100 3\n",
      "acc, n, k: 0.7585 100 7\n",
      "acc, n, k: 0.7497 100 15\n",
      "acc, n, k: 0.7408 100 25\n",
      "acc, n, k: 0.8101 1000 1\n",
      "acc, n, k: 0.8167 1000 3\n",
      "acc, n, k: 0.8153 1000 7\n",
      "acc, n, k: 0.8126 1000 15\n",
      "acc, n, k: 0.8049 1000 25\n",
      "max acc, max_n, max_k 0.8167 1000 3\n"
     ]
    }
   ],
   "source": [
    "max_accuary = 0\n",
    "max_k = 0\n",
    "max_n = 0\n",
    "\n",
    "for n in 10, 50, 100, 1000:\n",
    "    trainset = makeDataBase('FashionMNIST',partition='train', N=n, normalize=True)\n",
    "    trainX, trainy = list2ndarray(trainset)\n",
    "    for k in 1, 3, 7, 15, 25:\n",
    "        y_hat = KNN_predict(trainX, trainy, valX, k)\n",
    "        accuracy = compute_accuracy(y_hat, valy)\n",
    "        print(\"acc, n, k:\", accuracy, n, k)\n",
    "\n",
    "        if accuracy > max_accuary:\n",
    "            max_accuary = accuracy\n",
    "            max_k = k\n",
    "            max_n = n\n",
    "\n",
    "print(\"max acc, max_n, max_k\", max_accuary, max_n, max_k)\n",
    "# max acc, max_n, max_k 0.8167 1000 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a6fdb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accurary using N = 1000 and k = 3 is 0.8016\n"
     ]
    }
   ],
   "source": [
    "# Calc accurary using max k and n\n",
    "# test_accuracy = compute_accuracy(y_hat, valy)\n",
    "trainset = makeDataBase('FashionMNIST',partition='train',N=1000, normalize=True)# Try different N:10/50/100/1000;\n",
    "trainX, trainy = list2ndarray(trainset)\n",
    "y_hat = KNN_predict(trainX, trainy, testX, k)\n",
    "accuracy = compute_accuracy(y_hat, testy)\n",
    "\n",
    "print(\"best accurary using N = 1000 and k = 3 is\", accuracy)\n",
    "# best accurary using N = 1000 and k = 3 is 0.8016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3bb41",
   "metadata": {},
   "source": [
    "### Problem 7 Observation\n",
    "- The bigger the training size (N), the better the accurary.\n",
    "- For neighbors k, we should avoid extreme values, such as k = 1 or k = 100. \n",
    "- If k is too small, although the model will fit the training data almost perfectly, it will not generalize well on the test set.\n",
    "- If k is too large, the model will incorperate too many neighbors, which are too far away from the data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X,y, max_epoch=20, lr=1., lr_decay=0.95, stop_threshold=0.02):\n",
    "    '''\n",
    "    Outputs:\n",
    "        W (array)             : numpy array with size (num_classes, D)\n",
    "        b (array)             : numpy array with size (num_classes,)\n",
    "    '''\n",
    "    C = 10 # number of classes\n",
    "    D = len(X[0]) # number of features\n",
    "    N = len(X) # number of samples\n",
    "    W = np.random.rand(D, C) * 0.01 # weight matrix, each column is a class\n",
    "    b = np.random.rand(C) * 0.01 # bias vector\n",
    "\n",
    "    while max_epoch > 0:\n",
    "        update_cnt = 0.0\n",
    "        for i in range(N):\n",
    "            each_class = np.array(np.matmul(X[i], W) + b)\n",
    "            best_class = each_class.argmax()\n",
    "            if best_class != y[i]:\n",
    "                W[:, best_class] -= lr * X[i].transpose()\n",
    "                W[:, y[i]] += lr * X[i].transpose()\n",
    "                b[best_class] -= lr\n",
    "                b[y[i]] += lr\n",
    "                update_cnt += 1\n",
    "\n",
    "        if update_cnt / N < stop_threshold:\n",
    "            break\n",
    "\n",
    "        max_epoch -= 1\n",
    "        lr *= lr_decay\n",
    "\n",
    "    return W.transpose(), b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perceptron(X, W, b):\n",
    "    '''\n",
    "    Outputs:\n",
    "        y_hat (array): numpy array with size (N,)\n",
    "    '''\n",
    "    N = len(X)\n",
    "    y_hat = np.zeros(N, dtype=int)\n",
    "    y_matrix = np.matmul(X, W.transpose()) + b\n",
    "    for i in range(N):\n",
    "        y_hat[i] = y_matrix[i].argmax()\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay_rate, acc 0.9 0.8009\n",
      "decay_rate, acc 0.5 0.8224\n",
      "decay_rate, acc 0.3 0.8252\n",
      "decay_rate, acc 0.1 0.8231\n",
      "decay_rate, acc 0.05 0.8229\n",
      "decay_rate, acc 0.01 0.8147\n",
      "best rate, acc 0.3 0.8252\n"
     ]
    }
   ],
   "source": [
    "# Tune lr on validation partition\n",
    "\n",
    "trainset = makeDataBase('FashionMNIST',partition='train',N=1000, normalize=True, shuffle=True)\n",
    "trainX, trainy = list2ndarray(trainset)\n",
    "\n",
    "best_accu = 0\n",
    "best_decay_rate = -1\n",
    "\n",
    "for decay_rate in 0.9, 0.5, 0.3, 0.1, 0.05, 0.01:\n",
    "    W, b = train_perceptron(trainX, trainy, lr=1, lr_decay=decay_rate) \n",
    "    y_hat = test_perceptron(valX, W, b)\n",
    "    accu = compute_accuracy(y_hat, valy)\n",
    "    if accu > best_accu:\n",
    "        best_accu = accu\n",
    "        best_decay_rate = decay_rate\n",
    "    print(\"decay_rate, acc\", decay_rate, accu)\n",
    "\n",
    "print(\"best rate, acc\", best_decay_rate, best_accu)\n",
    "# best rate, acc 0.3 0.8252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lr, acc 0.5 0.7655\n"
     ]
    }
   ],
   "source": [
    "# Test accu on test set\n",
    "lr = 0.5\n",
    "W, b = train_perceptron(trainX, trainy, lr=0.5)\n",
    "y_hat = test_perceptron(testX, W, b)\n",
    "accu = compute_accuracy(y_hat, testy)\n",
    "print(\"best lr, acc\", lr, accu)\n",
    "# best lr, acc 0.5 0.7655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 9 ... 9 9 9]\n",
      "un-shuffle acc 0.1194\n"
     ]
    }
   ],
   "source": [
    "trainset = makeDataBase('FashionMNIST',partition='train',N=1000, normalize=True, shuffle=False)\n",
    "trainX, trainy = list2ndarray(trainset)\n",
    "W, b = train_perceptron(trainX, trainy, lr=1.0)\n",
    "y_hat = test_perceptron(valX, W, b)\n",
    "accu = compute_accuracy(y_hat, valy)\n",
    "print(\"y_hat\", y_hat)\n",
    "# [9 9 9 ... 9 9 9]\n",
    "print(\"un-shuffle acc\", accu)\n",
    "# un-shuffle acc 0.1059"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d825b",
   "metadata": {},
   "source": [
    "# What do you observe? What could be the reason?\n",
    "\n",
    "- If no shuffle, the first N samples will c1 class, second N samples will be c2 class, ..., tenth N samples will be c10 class.  \n",
    "- When training on this dataset, after first N samples, c1 class's weight will be boosted, and other classes' weights negligible.\n",
    "- After second N samples, c2's weight will be high, and others weights negligible.\n",
    "- ...\n",
    "- After tenth N samples, c10's weight will be high, and other weights negligible.\n",
    "- Therefore, the trained weights will be dominated by c10, thus causing the prediction to be always class 10 (which is index 9 in y_hat).\n",
    "- Hence, when apply the model on a test set, the accurary will be close to 1/10, as the model will always predict index 9 class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f594f625523eedf37de17555ec746ece4289f4fa39150ea03385bfab3da2cc11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
